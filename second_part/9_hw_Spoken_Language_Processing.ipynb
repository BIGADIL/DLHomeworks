{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zahzrEdRCaxV"
   },
   "source": [
    "### Spoken Language Processing\n",
    "В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n",
    "\n",
    "Подумайте, как лучше предсказывать возраст (может быть разбить на группы?) и какой лосс использовать\n",
    "\n",
    "P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n",
    "\n",
    "Вопросы по заданию/материалам: @Nestyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3wSgHrbiEc8x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timit-utils==0.9.0\n",
      "  Downloading timit_utils-0.9.0-py3-none-any.whl (11 kB)\n",
      "Collecting SoundFile>=0.8.0\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 939.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from timit-utils==0.9.0) (3.5.3)\n",
      "Collecting python-speech-features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from timit-utils==0.9.0) (1.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from timit-utils==0.9.0) (1.23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from timit-utils==0.9.0) (1.4.3)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from SoundFile>=0.8.0->timit-utils==0.9.0) (1.15.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (4.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib->timit-utils==0.9.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas->timit-utils==0.9.0) (2022.2.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from cffi>=1.0->SoundFile>=0.8.0->timit-utils==0.9.0) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mater\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7->matplotlib->timit-utils==0.9.0) (1.15.0)\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py): started\n",
      "  Building wheel for python-speech-features (setup.py): finished with status 'done'\n",
      "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=f5431e6c34f95595b7917bd6e9b9e324abe8de5ffe23209c05c1a6c4b7d9ce28\n",
      "  Stored in directory: c:\\users\\mater\\appdata\\local\\pip\\cache\\wheels\\5b\\60\\87\\28af2605138deac93d162904df42b6fdda1dab9b8757c62aa3\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features, SoundFile, timit-utils\n",
      "Successfully installed SoundFile-0.12.1 python-speech-features-0.6 timit-utils-0.9.0\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torchaudio) (1.9.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch==1.9.0->torchaudio) (4.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n",
      "\"unzip\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install timit-utils==0.9.0\n",
    "!pip3 install torchaudio\n",
    "! wget https://ndownloader.figshare.com/files/10256148 \n",
    "!unzip -q 10256148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u0bovLZ0Ew5V"
   },
   "outputs": [],
   "source": [
    "import timit_utils as tu\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "import IPython\n",
    "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd-qfC9-DdnJ"
   },
   "source": [
    "## Задание 1\n",
    "Загрузите данные для обучения. Для этого:\n",
    "1. Скачайте датасет TIMIT (см семинар)\n",
    "2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n",
    "\n",
    "P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DhPyP4T5DdAD"
   },
   "outputs": [],
   "source": [
    "import timit_utils as tu\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch as t\n",
    "\n",
    "\n",
    "class timit_dataloader:\n",
    "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
    "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
    "        self.corpus = tu.Corpus(data_path)\n",
    "        with open(self.doc_file_path) as f:\n",
    "            self.id_age_dict = dict(\n",
    "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
    "                 for tmp in f.readlines()[39:]])\n",
    "        if train_mode:\n",
    "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
    "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
    "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
    "\n",
    "    def return_age(self, id):\n",
    "        return self.id_age_dict[id]\n",
    "\n",
    "    def return_data(self):\n",
    "        return self.trainset, self.validset, self.testset\n",
    "\n",
    "    def return_test(self):\n",
    "        return self.testset\n",
    "\n",
    "    def create_dataset(self, mode, age_mode=False):\n",
    "        global people\n",
    "        assert mode in ['train', 'valid', 'test']\n",
    "        if mode == 'train':\n",
    "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
    "        if mode == 'valid':\n",
    "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
    "        if mode == 'test':\n",
    "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
    "        spectrograms_and_targets = []\n",
    "        for person in tqdm(people):\n",
    "            try:\n",
    "                target = self.return_age(person.name)\n",
    "                for i in range(len(person.sentences)):\n",
    "                    spectrograms_and_targets.append(\n",
    "                        self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
    "            except Exception as e:\n",
    "                print(person.name, target)\n",
    "\n",
    "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
    "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def spec_to_image(spec, eps=1e-6):\n",
    "        mean = spec.mean()\n",
    "        std = spec.std()\n",
    "        spec_norm = (spec - mean) / (std + eps)\n",
    "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "        spec_scaled = spec_scaled.astype(np.uint8)\n",
    "        return spec_scaled\n",
    "\n",
    "    @staticmethod\n",
    "    def clasterize_by_age(age):\n",
    "        if age < 25:\n",
    "            return 0\n",
    "        elif age < 40:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n",
    "        spectrogram = librosa.feature.melspectrogram(y=amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
    "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
    "        target = self.clasterize_by_age(target)\n",
    "        return self.spec_to_image(np.float32(spectrogram)), target\n",
    "\n",
    "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
    "        spectrogram = librosa.feature.melspectrogram(y=amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
    "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
    "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
    "\n",
    "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:21<00:00, 16.29it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.44it/s]\n",
      "100%|██████████| 150/150 [00:09<00:00, 16.63it/s]\n"
     ]
    }
   ],
   "source": [
    "_timit_dataloader = timit_dataloader()\n",
    "train_data, valid_data, test_data = _timit_dataloader.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda mode\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'using {device} mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.FloatTensor(train_data[0]), torch.LongTensor(train_data[1]))\n",
    "valid_dataset = TensorDataset(torch.FloatTensor(valid_data[0]), torch.LongTensor(valid_data[1]))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(test_data[0]), torch.LongTensor(test_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpz1Q5VOFxLM"
   },
   "source": [
    "Простая сверточная сеть, ее можно дотюнить или поменять по желанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qF9fIVq7Dbwx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, window_sizes=(3, 4, 5), weight=None):\n",
    "        super(Model, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.convs = nn.ModuleList([\n",
    "            \n",
    "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
    "            for window_size in window_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * len(window_sizes), 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
    "        xs = []\n",
    "        for conv in self.convs:\n",
    "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
    "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
    "            x2 = F.dropout(x2, p=0.4)\n",
    "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
    "            xs.append(x2)\n",
    "        x = torch.cat(xs, 2)  # [B, F, window]\n",
    "\n",
    "        # FC\n",
    "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
    "        logits = F.dropout(x, p=0.3)\n",
    "        logits = self.fc1(x)  # [B, class]\n",
    "        probs = F.log_softmax(logits, dim=1)\n",
    "        return probs\n",
    "\n",
    "    def loss(self, probs, targets):\n",
    "        return nn.NLLLoss(self.weight)(probs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScCZEMvXHkmz"
   },
   "source": [
    "# Задание 2\n",
    "1. Обучите свой классификатор категории возраста\n",
    "2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n",
    "3. Какой подход оказался самым эффективным? Как думаете, почему?\n",
    "4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оригинальная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(3, 128), stride=(1, 1), padding=(2, 0))\n",
       "    (1): Conv2d(1, 128, kernel_size=(4, 128), stride=(1, 1), padding=(3, 0))\n",
       "    (2): Conv2d(1, 128, kernel_size=(5, 128), stride=(1, 1), padding=(4, 0))\n",
       "  )\n",
       "  (fc1): Linear(in_features=384, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "if device == torch.device('cuda'):\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_y = []\n",
    "    total_output = []\n",
    "    for X, y in iterator:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = model.loss(output, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "        optimizer.step()\n",
    "        total_y.append(y.cpu().detach())\n",
    "        total_output.append(output.argmax(axis=1).cpu().detach())\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), accuracy_score(torch.cat(total_output), torch.cat(total_y))\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_y = []\n",
    "    total_output = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in iterator:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            loss = model.loss(output, y)\n",
    "            total_y.append(y.cpu().detach())\n",
    "            total_output.append(output.argmax(axis=1).cpu().detach())\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), accuracy_score(torch.cat(total_output), torch.cat(total_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "CLIP = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(model, train_iterator, valid_iterator, optimizer, state_dict_name):\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, CLIP)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, valid_loss: {valid_loss:.4f}, valid_acc: {valid_acc:.4f}')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), state_dict_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]C:\\Users\\mater\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  3%|▎         | 1/30 [00:02<00:58,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 6.4256, train_acc: 0.5651, valid_loss: 1.0716, valid_acc: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:07<00:10,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7644, train_acc: 0.7277, valid_loss: 1.8668, valid_acc: 0.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:12<00:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5126, train_acc: 0.8166, valid_loss: 3.0777, valid_acc: 0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "loop(model, train_dataloader, valid_dataloader, optimizer, 'best-val-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss_model: 1.0681, test_acc_model: 0.6447\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best-val-model.pt'))\n",
    "test_loss_model, test_acc_model = evaluate(model, test_dataloader)\n",
    "print(f'test_loss_model: {test_loss_model:.4f}, test_acc_model: {test_acc_model:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на поведение модели в случае уменьшения и увеличения количества window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(2, 128), stride=(1, 1), padding=(1, 0))\n",
       "    (1): Conv2d(1, 128, kernel_size=(3, 128), stride=(1, 1), padding=(2, 0))\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_23 = Model(window_sizes=(2, 3))\n",
    "if device == torch.device('cuda'):\n",
    "    model_23.cuda()\n",
    "else:\n",
    "    model_23.cpu()\n",
    "model_23.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 6.0739, train_acc: 0.5691, valid_loss: 0.9350, valid_acc: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:05<00:09,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7124, train_acc: 0.7331, valid_loss: 1.2220, valid_acc: 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:10<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5629, train_acc: 0.7880, valid_loss: 1.9778, valid_acc: 0.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_23.parameters(), lr=5e-3)\n",
    "loop(model_23, train_dataloader, valid_dataloader, optimizer, 'best-val-model-23.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss_model_23: 0.9763, test_acc_model_23: 0.6453\n"
     ]
    }
   ],
   "source": [
    "model_23.load_state_dict(torch.load('best-val-model-23.pt'))\n",
    "test_loss_model_23, test_acc_model_23 = evaluate(model_23, test_dataloader)\n",
    "print(f'test_loss_model_23: {test_loss_model_23:.4f}, test_acc_model_23: {test_acc_model_23:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лосс упал, точность выросла. Двигаясь в сторону уменьшения модели, мы видим рост качества предсказаний.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(3, 128), stride=(1, 1), padding=(2, 0))\n",
       "    (1): Conv2d(1, 128, kernel_size=(4, 128), stride=(1, 1), padding=(3, 0))\n",
       "    (2): Conv2d(1, 128, kernel_size=(5, 128), stride=(1, 1), padding=(4, 0))\n",
       "    (3): Conv2d(1, 128, kernel_size=(6, 128), stride=(1, 1), padding=(5, 0))\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3456 = Model(window_sizes=(3, 4, 5, 6))\n",
    "if device == torch.device('cuda'):\n",
    "    model_3456.cuda()\n",
    "else:\n",
    "    model_3456.cpu()\n",
    "model_3456.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:26,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 7.0999, train_acc: 0.5543, valid_loss: 1.2209, valid_acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:07<00:11,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.8465, train_acc: 0.7311, valid_loss: 2.1638, valid_acc: 0.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:13<00:05,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5513, train_acc: 0.8166, valid_loss: 3.6887, valid_acc: 0.5720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_3456.parameters(), lr=5e-3)\n",
    "loop(model_3456, train_dataloader, valid_dataloader, optimizer, 'best-val-model-3456.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss_model_3456: 1.2493, test_acc_model_3456: 0.6213\n"
     ]
    }
   ],
   "source": [
    "model_3456.load_state_dict(torch.load('best-val-model-3456.pt'))\n",
    "test_loss_model_3456, test_acc_model_3456 = evaluate(model_3456, test_dataloader)\n",
    "print(f'test_loss_model_3456: {test_loss_model_3456:.4f}, test_acc_model_3456: {test_acc_model_3456:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лосс вырос, точность упала. Двигаясь в сторону усложнения модели, мы видим падение качества предсказаний.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(2, 128), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Model(window_sizes=(2,))\n",
    "if device == torch.device('cuda'):\n",
    "    model_2.cuda()\n",
    "else:\n",
    "    model_2.cpu()\n",
    "model_2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:19,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 3.2890, train_acc: 0.5517, valid_loss: 1.1407, valid_acc: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:04<00:07,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7481, train_acc: 0.7163, valid_loss: 1.1408, valid_acc: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:08<00:03,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6123, train_acc: 0.7614, valid_loss: 1.5565, valid_acc: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_2.parameters(), lr=5e-3)\n",
    "loop(model_2, train_dataloader, valid_dataloader, optimizer, 'best-val-model-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss_model_2: 0.9009, test_acc_model_2: 0.6807\n"
     ]
    }
   ],
   "source": [
    "model_2.load_state_dict(torch.load('best-val-model-2.pt'))\n",
    "test_loss_model_2, test_acc_model_2 = evaluate(model_2, test_dataloader)\n",
    "print(f'test_loss_model_2: {test_loss_model_2:.4f}, test_acc_model_2: {test_acc_model_2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лосс еще сильнее упал, а точность выросла. Несложно заметить, что изначальная модель сильно переобучалась на тренировочные данные. Вы постепенно уменьшили ее размер, что положительно сказалось на качестве.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Веса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 используемых класса сильно несбалансированны. 1 класс очень большой, 2 класс сильно меньше, 3 класс еще меньше. Накинем веса на функцию потерь, чтобы модель больше внимания обращала на самый редкий класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(2, 128), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight = Model(window_sizes=(2,), weight=torch.FloatTensor([1, 4, 5]).to(device))\n",
    "if device == torch.device('cuda'):\n",
    "    model_weight.cuda()\n",
    "else:\n",
    "    model_weight.cpu()\n",
    "model_weight.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:17,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.9757, train_acc: 0.5814, valid_loss: 0.8919, valid_acc: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:04<00:07,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5606, train_acc: 0.7309, valid_loss: 1.3156, valid_acc: 0.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:08<00:03,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.4477, train_acc: 0.7591, valid_loss: 2.0080, valid_acc: 0.6540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_weight.parameters(), lr=5e-3)\n",
    "loop(model_weight, train_dataloader, valid_dataloader, optimizer, 'best-val-model-weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss_model_weight: 0.7910, test_acc_model_weight: 0.6913\n"
     ]
    }
   ],
   "source": [
    "model_weight.load_state_dict(torch.load('best-val-model-weight.pt'))\n",
    "test_loss_model_weight, test_acc_model_weight = evaluate(model_weight, test_dataloader)\n",
    "print(f'test_loss_model_weight: {test_loss_model_weight:.4f}, test_acc_model_weight: {test_acc_model_weight:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лосс упал, но здесь он с весами, поэтому сравнивать с предыдущим экспериментом нельзя. А вот точность выросла, т.е. взвешенный лосс дает прирост качества.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти на 5% повышена точность за счет уменьшения модели и добавления взвешенного лосса. Это произшло из-за сильного переобучения исходной модели на тренировочных данных, а также несбалансированности классов.\n",
    "\n",
    "Такой классификатор возрастных групп можно использовать, например, при ранжировании поисковых голосовых запросов. Поскольку интересы людей разных возрастов различаются, такой классификатор поможет лучше выдавать результаты поиска пользователям."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
